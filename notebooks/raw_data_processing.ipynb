{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "warming-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "catholic-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = \"../utils/transcripts_download/raw_corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loaded-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RAW_DATA_PATH, os.listdir(RAW_DATA_PATH)[0]), encoding=\"utf-8\") as file_:\n",
    "    lines = file_.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "figured-fifty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '\\t\\t\\t\\tScene: A corridor at a sperm bank.\\n',\n",
       " 'Sheldon: So if a photon is directed through a plane with two slits in it and either slit is observed it will not go through both slits. If it’s unobserved it will, however, if it’s observed after it’s left the plane but before it hits its target, it will not have gone through both slits.\\n',\n",
       " 'Leonard: Agreed, what’s your point?\\n',\n",
       " 'Sheldon: There’s no point, I just think it’s a good idea for a tee-shirt. \\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "descending-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the line contains : , easy to verify by checking len after split.\n",
    "#go line, by line and check if it's a sheldon's dialog, if yes then take it's preceding one as a input. \n",
    "#if sheldon's dialog do not have any preceding dialog, then we can skip it. \n",
    "#if sheldon's dialog is the first one after the scene changes, then TBD. \n",
    "#removing all description written inside ()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "SENTENCE_INSIDE_BRACKETS_PATTERN = re.compile(r\"\\([\\w\\s,.]*\\)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "visible-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = []\n",
    "in_speaker = []\n",
    "output = []\n",
    "out_speaker = []\n",
    "col_names = ['in_speaker', 'input', 'out_speaker', 'output']\n",
    "\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    splitted_line = line.split(\":\")\n",
    "    \n",
    "    if len(splitted_line)==2:\n",
    "        speaker, dialog = splitted_line\n",
    "        \n",
    "        if speaker.lower() == \"sheldon\":  \n",
    "            \n",
    "            #take the preceding dialog. \n",
    "            prev_line = lines[idx-1].split(\":\")\n",
    "            \n",
    "            if len(prev_line) == 2:\n",
    "                prev_speaker, pre_dialog = prev_line\n",
    "                \n",
    "                if prev_speaker.lower() != \"sheldon\":\n",
    "                    pre_dialog = SENTENCE_INSIDE_BRACKETS_PATTERN.sub(\"\", pre_dialog)\n",
    "                    dialog = SENTENCE_INSIDE_BRACKETS_PATTERN.sub(\"\", dialog)\n",
    "                    \n",
    "                    input_.append(pre_dialog.strip())\n",
    "                    in_speaker.append(prev_speaker.strip())\n",
    "                    output.append(dialog.strip())\n",
    "                    out_speaker.append(speaker.strip())\n",
    "                    \n",
    "#write file to the csv file.\n",
    "cache_df = pd.DataFrame({\"in_speaker\": in_speaker, \"input\": input_, \"out_speaker\":out_speaker, \"output\":output})  \n",
    "\n",
    "\n",
    "if not os.path.isfile('processed_data.csv'):\n",
    "    cache_df.to_csv('processed_data.csv', header=col_names)\n",
    "else: # else it exists so append without writing the header\n",
    "    cache_df.to_csv('processed_data.csv', mode='a', header=False)\n",
    "\n",
    "#                     with open('processed_data.csv', 'w', newline='') as csvfile:\n",
    "#                         writer = csv.DictWriter(csvfile, fieldnames=col_names)\n",
    "#                         writer.writerow({'in_speaker': prev_speaker.strip() , 'input': pre_dialog.strip() , 'out_speaker':speaker.strip(), 'output':dialog.strip()})\n",
    "                    \n",
    "#                     print(f\"input: {prev_speaker.strip()} : {pre_dialog.strip()}\")\n",
    "#                     print(f\"output: {speaker} : {dialog.strip()}\")\n",
    "\n",
    "                    \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "frequent-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dialogs_to_csv(lines):\n",
    "    \n",
    "    input_ = []\n",
    "    in_speaker = []\n",
    "    output = []\n",
    "    out_speaker = []\n",
    "    col_names = ['in_speaker', 'input', 'out_speaker', 'output']\n",
    "\n",
    "\n",
    "    for idx, line in enumerate(lines):\n",
    "        splitted_line = line.split(\":\")\n",
    "\n",
    "        if len(splitted_line)==2:\n",
    "            speaker, dialog = splitted_line\n",
    "            speaker = SENTENCE_INSIDE_BRACKETS_PATTERN.sub(\"\", speaker)\n",
    "\n",
    "            if speaker.lower() == \"sheldon\":  \n",
    "\n",
    "                #take the preceding dialog. \n",
    "                prev_line = lines[idx-1].split(\":\")\n",
    "\n",
    "                if len(prev_line) == 2:\n",
    "                    prev_speaker, pre_dialog = prev_line\n",
    "                    prev_speaker = SENTENCE_INSIDE_BRACKETS_PATTERN.sub(\"\", prev_speaker)\n",
    "\n",
    "                    if prev_speaker.lower() != \"sheldon\":\n",
    "                        pre_dialog = SENTENCE_INSIDE_BRACKETS_PATTERN.sub(\"\", pre_dialog)\n",
    "                        dialog = SENTENCE_INSIDE_BRACKETS_PATTERN.sub(\"\", dialog)\n",
    "\n",
    "                        input_.append(pre_dialog.strip())\n",
    "                        in_speaker.append(prev_speaker.strip())\n",
    "                        output.append(dialog.strip())\n",
    "                        out_speaker.append(speaker.strip())\n",
    "\n",
    "    #write file to the csv file.\n",
    "    cache_df = pd.DataFrame({\"in_speaker\": in_speaker, \"input\": input_, \"out_speaker\":out_speaker, \"output\":output})  \n",
    "\n",
    "    if not os.path.isfile('processed_data.csv'):\n",
    "        cache_df.to_csv('processed_data.csv', header=col_names, encoding='utf-8')\n",
    "    else: # else it exists so append without writing the header\n",
    "        cache_df.to_csv('processed_data.csv', mode='a', header=False, encoding='utf-8')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "grateful-fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1_1.txt is done\n",
      "processing 1_10.txt is done\n",
      "processing 1_11.txt is done\n",
      "processing 1_12.txt is done\n",
      "processing 1_13.txt is done\n",
      "processing 1_14.txt is done\n",
      "processing 1_15.txt is done\n",
      "processing 1_16.txt is done\n",
      "processing 1_17.txt is done\n",
      "processing 1_2.txt is done\n",
      "processing 1_3.txt is done\n",
      "processing 1_4.txt is done\n",
      "processing 1_5.txt is done\n",
      "processing 1_6.txt is done\n",
      "processing 1_7.txt is done\n",
      "processing 1_8.txt is done\n",
      "processing 1_9.txt is done\n",
      "processing 2_1.txt is done\n",
      "processing 2_11.txt is done\n",
      "processing 2_12.txt is done\n",
      "processing 2_13.txt is done\n",
      "processing 2_14.txt is done\n",
      "processing 2_15.txt is done\n",
      "processing 2_16.txt is done\n",
      "processing 2_17.txt is done\n",
      "processing 2_18.txt is done\n",
      "processing 2_19.txt is done\n",
      "processing 2_2.txt is done\n",
      "processing 2_20.txt is done\n",
      "processing 2_21.txt is done\n",
      "processing 2_22.txt is done\n",
      "processing 2_23.txt is done\n",
      "processing 2_3.txt is done\n",
      "processing 2_4.txt is done\n",
      "processing 2_5.txt is done\n",
      "processing 2_6.txt is done\n",
      "processing 2_7.txt is done\n",
      "processing 2_9.txt is done\n",
      "processing 3_1.txt is done\n",
      "processing 3_10.txt is done\n",
      "processing 3_11.txt is done\n",
      "processing 3_12.txt is done\n",
      "processing 3_13.txt is done\n",
      "processing 3_14.txt is done\n",
      "processing 3_15.txt is done\n",
      "processing 3_16.txt is done\n",
      "processing 3_17.txt is done\n",
      "processing 3_18.txt is done\n",
      "processing 3_19.txt is done\n",
      "processing 3_2.txt is done\n",
      "processing 3_20.txt is done\n",
      "processing 3_21.txt is done\n",
      "processing 3_22.txt is done\n",
      "processing 3_23.txt is done\n",
      "processing 3_3.txt is done\n",
      "processing 3_4.txt is done\n",
      "processing 3_5.txt is done\n",
      "processing 3_6.txt is done\n",
      "processing 3_7.txt is done\n",
      "processing 3_8.txt is done\n",
      "processing 3_9.txt is done\n",
      "processing 4_1.txt is done\n",
      "processing 4_10.txt is done\n",
      "processing 4_11.txt is done\n",
      "processing 4_12.txt is done\n",
      "processing 4_13.txt is done\n",
      "processing 4_14.txt is done\n",
      "processing 4_15.txt is done\n",
      "processing 4_16.txt is done\n",
      "processing 4_17.txt is done\n",
      "processing 4_18.txt is done\n",
      "processing 4_19.txt is done\n",
      "processing 4_2.txt is done\n",
      "processing 4_20.txt is done\n",
      "processing 4_21.txt is done\n",
      "processing 4_22.txt is done\n",
      "processing 4_23.txt is done\n",
      "processing 4_24.txt is done\n",
      "processing 4_3.txt is done\n",
      "processing 4_4.txt is done\n",
      "processing 4_5.txt is done\n",
      "processing 4_6.txt is done\n",
      "processing 4_7.txt is done\n",
      "processing 4_8.txt is done\n",
      "processing 4_9.txt is done\n",
      "processing 5_1.txt is done\n",
      "processing 5_10.txt is done\n",
      "processing 5_11.txt is done\n",
      "processing 5_12.txt is done\n",
      "processing 5_13.txt is done\n",
      "processing 5_14.txt is done\n",
      "processing 5_15.txt is done\n",
      "processing 5_16.txt is done\n",
      "processing 5_17.txt is done\n",
      "processing 5_18.txt is done\n",
      "processing 5_19.txt is done\n",
      "processing 5_2.txt is done\n",
      "processing 5_20.txt is done\n",
      "processing 5_21.txt is done\n",
      "processing 5_22.txt is done\n",
      "processing 5_23.txt is done\n",
      "processing 5_24.txt is done\n",
      "processing 5_3.txt is done\n",
      "processing 5_4.txt is done\n",
      "processing 5_5.txt is done\n",
      "processing 5_6.txt is done\n",
      "processing 5_7.txt is done\n",
      "processing 5_8.txt is done\n",
      "processing 5_9.txt is done\n",
      "processing 6_1.txt is done\n",
      "processing 6_10.txt is done\n",
      "processing 6_11.txt is done\n",
      "processing 6_12.txt is done\n",
      "processing 6_13.txt is done\n",
      "processing 6_14.txt is done\n",
      "processing 6_15.txt is done\n",
      "processing 6_16.txt is done\n",
      "processing 6_17.txt is done\n",
      "processing 6_18.txt is done\n",
      "processing 6_19.txt is done\n",
      "processing 6_2.txt is done\n",
      "processing 6_20.txt is done\n",
      "processing 6_21.txt is done\n",
      "processing 6_22.txt is done\n",
      "processing 6_3.txt is done\n",
      "processing 6_4.txt is done\n",
      "processing 6_5.txt is done\n",
      "processing 6_6.txt is done\n",
      "processing 6_7.txt is done\n",
      "processing 6_8.txt is done\n",
      "processing 6_9.txt is done\n",
      "processing 7_1.txt is done\n",
      "processing 7_10.txt is done\n",
      "processing 7_11.txt is done\n",
      "processing 7_12.txt is done\n",
      "processing 7_13.txt is done\n",
      "processing 7_14.txt is done\n",
      "processing 7_15.txt is done\n",
      "processing 7_16.txt is done\n",
      "processing 7_17.txt is done\n",
      "processing 7_18.txt is done\n",
      "processing 7_19.txt is done\n",
      "processing 7_2.txt is done\n",
      "processing 7_20.txt is done\n",
      "processing 7_21.txt is done\n",
      "processing 7_22.txt is done\n",
      "processing 7_23.txt is done\n",
      "processing 7_24.txt is done\n",
      "processing 7_3.txt is done\n",
      "processing 7_4.txt is done\n",
      "processing 7_5.txt is done\n",
      "processing 7_6.txt is done\n",
      "processing 7_7.txt is done\n",
      "processing 7_8.txt is done\n",
      "processing 7_9.txt is done\n",
      "processing 8_1.txt is done\n",
      "processing 8_10.txt is done\n",
      "processing 8_11.txt is done\n",
      "processing 8_12.txt is done\n",
      "processing 8_13.txt is done\n",
      "processing 8_14.txt is done\n",
      "processing 8_15.txt is done\n",
      "processing 8_16.txt is done\n",
      "processing 8_17.txt is done\n",
      "processing 8_18.txt is done\n",
      "processing 8_19.txt is done\n",
      "processing 8_2.txt is done\n",
      "processing 8_20.txt is done\n",
      "processing 8_21.txt is done\n",
      "processing 8_22.txt is done\n",
      "processing 8_23.txt is done\n",
      "processing 8_24.txt is done\n",
      "processing 8_3.txt is done\n",
      "processing 8_4.txt is done\n",
      "processing 8_6.txt is done\n",
      "processing 8_7.txt is done\n",
      "processing 8_8.txt is done\n",
      "processing 8_9.txt is done\n",
      "processing 9_1.txt is done\n",
      "processing 9_10.txt is done\n",
      "processing 9_11.txt is done\n",
      "processing 9_12.txt is done\n",
      "processing 9_13.txt is done\n",
      "processing 9_14.txt is done\n",
      "processing 9_15.txt is done\n",
      "processing 9_16.txt is done\n",
      "processing 9_17.txt is done\n",
      "processing 9_18.txt is done\n",
      "processing 9_19.txt is done\n",
      "processing 9_2.txt is done\n",
      "processing 9_20.txt is done\n",
      "processing 9_21.txt is done\n",
      "processing 9_22.txt is done\n",
      "processing 9_23.txt is done\n",
      "processing 9_24.txt is done\n",
      "processing 9_3.txt is done\n",
      "processing 9_4.txt is done\n",
      "processing 9_5.txt is done\n",
      "processing 9_6.txt is done\n",
      "processing 9_7.txt is done\n",
      "processing 9_8.txt is done\n",
      "processing 9_9.txt is done\n"
     ]
    }
   ],
   "source": [
    "transcripts = os.listdir(RAW_DATA_PATH)\n",
    "\n",
    "\n",
    "for file_count in range(len(transcripts)):\n",
    "    with open(os.path.join(RAW_DATA_PATH, transcripts[file_count]), encoding=\"utf-8\") as file_:\n",
    "        lines = file_.readlines()\n",
    "    \n",
    "    write_dialogs_to_csv(lines)\n",
    "    \n",
    "    print(f\"processing {transcripts[file_count]} is done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "governmental-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"./processed_corpus/x/y/z/processed_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "outside-aurora",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./processed_corpus/x/y/z'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/\".join(x.split(\"/\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-olive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
